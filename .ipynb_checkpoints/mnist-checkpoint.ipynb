{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "69lZh_0Goz1o"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "T1bIhO6x7H1q"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "all_train_data = torchvision.datasets.MNIST('.', train = True, download = True, transform = transform)\n",
    "test_set = torchvision.datasets.MNIST('.', train = False, download = True, transform = transform)\n",
    "train_size = int(0.9 * len(all_train_data))\n",
    "train_set, val_set = torch.utils.data.random_split(all_train_data, [train_size, len(all_train_data) - train_size])\n",
    "\n",
    "batch_size = 24\n",
    "train_dataloader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "val_dataloader = DataLoader(val_set, batch_size = batch_size, shuffle = False)\n",
    "test_dataloader = DataLoader(test_set, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XUxC8Fm9Rl5",
    "outputId": "26d1fbf1-920a-4710-8059-4edabf12402d"
   },
   "outputs": [],
   "source": [
    "#DATA AUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "UCeGp9bCAb1D",
    "outputId": "fc318384-3354-492a-bf72-5d3d1e53f283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sample image\n",
    "image, label = train_set[0]\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "jY4FLklABilS"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes)\n",
    "        )\n",
    "    def forward(self, x): \n",
    "        x = torch.flatten(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams and model def\n",
    "lr = 1e-4\n",
    "epochs = 100\n",
    "linear_model = MLP(10)\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr = lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x18816 and 784x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      7\u001b[0m     img, label \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mforward(img)\n",
      "Cell \u001b[0;32mIn[54], line 11\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x18816 and 784x100)"
     ]
    }
   ],
   "source": [
    "#training\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        img, label = batch\n",
    "        outputs = linear_model.forward(img)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
